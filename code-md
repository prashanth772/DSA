import cv2
import mediapipe as mp
import numpy as np
import random
import string
from sklearn.ensemble import RandomForestClassifier

# Initialize MediaPipe Hands
mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    max_num_hands=1,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7)

# Initialize random forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)

# Define constants for screen resolution and font size
SCREEN_WIDTH, SCREEN_HEIGHT = 640, 480
FONT = cv2.FONT_HERSHEY_SIMPLEX
FONT_SIZE = 1

# Define a function to generate a random string of characters
def generate_random_string(length):
    return ''.join(random.choice(string.ascii_uppercase) for i in range(length))

# Define a function to preprocess the image and extract the index finger tip
def preprocess_image(image):
    # Convert the image from BGR to RGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Flip the image horizontally for a mirrored selfie view
    image = cv2.flip(image, 1)

    # Process the image with MediaPipe Hands
    results = hands.process(image)

    # Check if hands are detected
    if results.multi_hand_landmarks:
        # Get landmarks for the first hand detected
        hand_landmarks = results.multi_hand_landmarks[0]

        # Get the x and y coordinates of the tip of the index finger
        index_finger_x = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image.shape[1]
        index_finger_y = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image.shape[0]

        # Return the coordinates of the index finger tip
        return index_finger_x, index_finger_y
    
    # If no hands are detected, return None
    return None

# Define a function to draw on the image
def draw_on_image(image, x, y, text):
    # Draw a circle at the current position
    cv2.circle(image, (x, y), 5, (0, 255, 0), -1)

    # Draw the current character on the image
    cv2.putText(image, text, (20, 50), FONT, FONT_SIZE, (0, 255, 0), 2, cv2.LINE_AA)

# Define a function to train the classifier on the data
def train_classifier(X, y):
    clf.fit(X, y)

# Define a function to predict the character drawn on the screen
def predict_character(X):
    return clf.predict(X)[0]

# Initialize variables for the drawing process
drawing = False
last_x, last_y = None, None
current_text = ''
X, y = [], []

# Start the video capture
cap = cv2.VideoCapture(0)

# Loop through each frame of the video
while True:
    # Read the current frame
    ret, frame = cap.read()

    # If the frame was not read successfully, exit the loop
    if not ret:
        break

    # Preprocess the image and get the index finger tip
    index_finger = preprocess_image(frame)

    # If the index finger is detected, update the drawing status and draw on the image
    # If the index finger is detected, update the drawing status and draw on the image
    if index_finger is not None:
        # Update the drawing status
        if not drawing:
            drawing = True
            current_text = generate_random_string(1)
            X.append(index_finger)
            y.append(current_text)
        else:
            # Draw a line from the last position to the current position
            if last_x is not None and last_y is not None:
                cv2.line(frame, (last_x, last_y), (int(index_finger[0]), int(index_finger[1])), (0, 255, 0), 5)
            
            # Update the position of the index finger tip
            last_x, last_y = int(index_finger[0]), int(index_finger[1])

    else:
        # If the index finger is not detected, reset the drawing status
        if drawing:
            drawing = False
            last_x, last_y = None, None
            X = np.array(X)
            y = np.array(y)
            
            # Train the classifier on the data
            train_classifier(X, y)
            
            # Clear the data arrays
            X, y = [], []
            
            # Print the predicted character on the image
            predicted_char = predict_character([index_finger])
            draw_on_image(frame, int(index_finger[0]), int(index_finger[1]), predicted_char)

    # Display the image
    cv2.imshow('Finger Air Writing', frame)

    # Exit the loop if the 'q' key is pressed
    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
